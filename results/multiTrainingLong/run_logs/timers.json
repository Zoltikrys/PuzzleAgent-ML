{
    "name": "root",
    "gauges": {
        "PuzzleAgent.Policy.Entropy.mean": {
            "value": 1.7316009998321533,
            "min": 1.7316009998321533,
            "max": 2.111443042755127,
            "count": 63
        },
        "PuzzleAgent.Policy.Entropy.sum": {
            "value": 21139.384765625,
            "min": 19726.240234375,
            "max": 35472.2421875,
            "count": 63
        },
        "PuzzleAgent.Environment.EpisodeLength.mean": {
            "value": 13.44484412470024,
            "min": 12.127332601536773,
            "max": 199.0,
            "count": 63
        },
        "PuzzleAgent.Environment.EpisodeLength.sum": {
            "value": 11213.0,
            "min": 10746.0,
            "max": 16119.0,
            "count": 63
        },
        "PuzzleAgent.Step.mean": {
            "value": 755867.0,
            "min": 11803.0,
            "max": 755867.0,
            "count": 63
        },
        "PuzzleAgent.Step.sum": {
            "value": 755867.0,
            "min": 11803.0,
            "max": 755867.0,
            "count": 63
        },
        "PuzzleAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -1.041033387184143,
            "min": -2.94669508934021,
            "max": 0.33588287234306335,
            "count": 63
        },
        "PuzzleAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -868.2218017578125,
            "min": -953.55712890625,
            "max": 20.824737548828125,
            "count": 63
        },
        "PuzzleAgent.Environment.CumulativeReward.mean": {
            "value": -1.216791379437458,
            "min": -5.797650233904521,
            "max": -1.1816634000324813,
            "count": 63
        },
        "PuzzleAgent.Environment.CumulativeReward.sum": {
            "value": -1014.80401045084,
            "min": -1081.2220110297203,
            "max": -334.8030121922493,
            "count": 63
        },
        "PuzzleAgent.Policy.ExtrinsicReward.mean": {
            "value": -1.216791379437458,
            "min": -5.797650233904521,
            "max": -1.1816634000324813,
            "count": 63
        },
        "PuzzleAgent.Policy.ExtrinsicReward.sum": {
            "value": -1014.80401045084,
            "min": -1081.2220110297203,
            "max": -334.8030121922493,
            "count": 63
        },
        "PuzzleAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 63
        },
        "PuzzleAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 63
        },
        "PuzzleAgent.Losses.PolicyLoss.mean": {
            "value": 0.09584915580092566,
            "min": 0.08850830507296276,
            "max": 0.10532138880081608,
            "count": 60
        },
        "PuzzleAgent.Losses.PolicyLoss.sum": {
            "value": 0.09584915580092566,
            "min": 0.08850830507296276,
            "max": 0.10532138880081608,
            "count": 60
        },
        "PuzzleAgent.Losses.ValueLoss.mean": {
            "value": 0.020307564025526827,
            "min": 0.004151445089263375,
            "max": 0.22807913951880063,
            "count": 60
        },
        "PuzzleAgent.Losses.ValueLoss.sum": {
            "value": 0.020307564025526827,
            "min": 0.004151445089263375,
            "max": 0.22807913951880063,
            "count": 60
        },
        "PuzzleAgent.Policy.LearningRate.mean": {
            "value": 0.00027500477499841107,
            "min": 0.00027500477499841107,
            "max": 0.0002994599001800333,
            "count": 60
        },
        "PuzzleAgent.Policy.LearningRate.sum": {
            "value": 0.00027500477499841107,
            "min": 0.00027500477499841107,
            "max": 0.0002994599001800333,
            "count": 60
        },
        "PuzzleAgent.Policy.Epsilon.mean": {
            "value": 0.19166825555555553,
            "min": 0.19166825555555553,
            "max": 0.19981996666666668,
            "count": 60
        },
        "PuzzleAgent.Policy.Epsilon.sum": {
            "value": 0.19166825555555553,
            "min": 0.19166825555555553,
            "max": 0.19981996666666668,
            "count": 60
        },
        "PuzzleAgent.Policy.Beta.mean": {
            "value": 0.0009175157300000002,
            "min": 0.0009175157300000002,
            "max": 0.0009982176699999995,
            "count": 60
        },
        "PuzzleAgent.Policy.Beta.sum": {
            "value": 0.0009175157300000002,
            "min": 0.0009175157300000002,
            "max": 0.0009982176699999995,
            "count": 60
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1746451598",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Christopher\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn Assets/config/ppo/trainer_config.yaml --run-id=multiTrainingLong --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1746452045"
    },
    "total": 447.3294726000004,
    "count": 1,
    "self": 0.005934700000580051,
    "children": {
        "run_training.setup": {
            "total": 0.06603250000080152,
            "count": 1,
            "self": 0.06603250000080152
        },
        "TrainerController.start_learning": {
            "total": 447.257505399999,
            "count": 1,
            "self": 0.3542903000670776,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.333601500000441,
                    "count": 1,
                    "self": 6.333601500000441
                },
                "TrainerController.advance": {
                    "total": 440.51937489992997,
                    "count": 33707,
                    "self": 0.3362143998074316,
                    "children": {
                        "env_step": {
                            "total": 247.457565599987,
                            "count": 33707,
                            "self": 226.73337270028242,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 20.49759089997133,
                                    "count": 33707,
                                    "self": 1.1825845999046578,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 19.31500630006667,
                                            "count": 27318,
                                            "self": 19.31500630006667
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.2266019997332478,
                                    "count": 33706,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 441.00492739990295,
                                            "count": 33706,
                                            "is_parallel": true,
                                            "self": 245.80527909975535,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00035629999911179766,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0001384999995934777,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00021779999951831996,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00021779999951831996
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 195.1992920001485,
                                                    "count": 33706,
                                                    "is_parallel": true,
                                                    "self": 3.0011541002259037,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 6.209018599873161,
                                                            "count": 33706,
                                                            "is_parallel": true,
                                                            "self": 6.209018599873161
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 178.65244020003774,
                                                            "count": 33706,
                                                            "is_parallel": true,
                                                            "self": 178.65244020003774
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 7.336679100011679,
                                                            "count": 33706,
                                                            "is_parallel": true,
                                                            "self": 3.0657205999923463,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 4.270958500019333,
                                                                    "count": 67412,
                                                                    "is_parallel": true,
                                                                    "self": 4.270958500019333
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 192.72559490013555,
                            "count": 33706,
                            "self": 0.5941293001415033,
                            "children": {
                                "process_trajectory": {
                                    "total": 36.04446059998918,
                                    "count": 33706,
                                    "self": 35.9816721999905,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.06278839999868069,
                                            "count": 1,
                                            "self": 0.06278839999868069
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 156.08700500000486,
                                    "count": 61,
                                    "self": 57.39983010007927,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 98.6871748999256,
                                            "count": 35622,
                                            "self": 98.6871748999256
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.000009307172149e-07,
                    "count": 1,
                    "self": 6.000009307172149e-07
                },
                "TrainerController._save_models": {
                    "total": 0.05023810000056983,
                    "count": 1,
                    "self": 0.005255200001556659,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.04498289999901317,
                            "count": 1,
                            "self": 0.04498289999901317
                        }
                    }
                }
            }
        }
    }
}